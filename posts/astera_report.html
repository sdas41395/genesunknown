<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synthetic Biology Short Story</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <a href="../index.html">← Back to Home</a>
    </header>
    <hr/>
    <h1>Synthetic Biology Short Story</h1>
    <p>

        To whomever it concerns, 
Throughout my career, I’ve worked at the intersection of engineering, biotechnology and healthcare. I used these opportunities to hone my skills in conceptualizing software products based on scientists’ requirements, designing and building software applications, and delivering a tangible impact to scientists and physicians in academia and industry alike. In my role as the sole engineer at Denali therapeutics, I built software solutions alongside different -omics groups from initial white boarding to full production to aid in Alzheimer’s therapeutics. At Octant, I led multiple software projects from automated experiment design to machine learning analysis pipelines. These multifaceted roles were a combination of my skills in both software development and scientific collaboration in order to provide seamless solutions that would directly impact bottom lines of our internal teams such as screening and high throughput chemistry. These roles of project management and software development across biotech startups has helped me develop a rigorous work ethic and the ability to plan, design, document, as well as code large scale software projects. I want to apply these skills to provide better, cheaper, and faster transformational technology at a larger scale in this new age of biology with Astera’s support. As I gather user stories to validate my various hypotheses presented below, I anticipate embracing a high level of flexibility as needed to continuously validate my plan and ideas through fast iteration cycles. 
The world is experiencing a revolution in computing. Hardware improvements in chip design and manufacturing has resulted in exponential growth in our ability to ingest, transform, predict and increasingly consume data. The sheer quantity and scale of scientific data is no longer a bottleneck, but a feature that we can use to power new algorithms to give us insight on biological pathways and systems. These generated insights will be the rationale behind future life saving drugs and medicines. However, to fully utilize these breakthroughs, we must have both high-quality data that is standardized and contextualized as well as the quantity of data that is large enough for these systems to learn. In response to this, screening libraries grow exponentially larger and automation is quickly becoming a standard at biotechs looking to iterate quickly, resulting in a fast paced growth in demand for testable chemical compounds. The physical and material demands for high throughput chemistry will be the limiting factor. To fuel this demand for compounds, there is a need to optimize logistical software and incorporate advances in machine learning.
	While being the backbone for scientific discovery, there is a lack of resources available for academics in compound procurement and management. Improvements in this process for academics will have exponential effects downstream for healthcare as a whole. Keeping this product open and free for academic institutions will drive future innovation and hopefully help deliver life saving medicines to patients in need.
The barriers to compound procurement and management can be divided into three main challenges. Firstly, the current process of vendor selection for compounds is restricted in providing a comprehensive landscape of what is available. Secondly, the compounds are also nearly impossible to manually scan, which ends up comprising chemist time and resources. Finally, the tracking of compound orders and logistics is one of the biggest costs for any research organization, and it distinctly suffers from terrible UI and outdated software. A better system needs to be in place to factor in logistical and industrial realities as chemists must navigate the intricacies of sourcing vendors, negotiating prices, and figuring out packaging and shipping times. All of these processes are still manually managed through email, Excel or overpriced or outdated software.
In order to address these barriers, my initial solution focuses on building a software platform that horizontally captures users through the procurement and management pipeline. The first feature encompasses vendor catalog aggregation and suggestion. This platform provides seamless look-up of vendor catalogs by the compounds’ chemical makeup as well as additional generated chemical properties that chemists can use to further narrow their search criteria. The software suggests structurally and chemically similar compounds based on similarity or substructure search of all collected catalogs. These features will accelerate a chemist’s ability to not only find vendors but also fine tune their compounds based on the entirety of the commercially available chemical space. After selecting the compounds and the vendors, users submit orders and track each stage of the order through a dashboard functioning as the key part of the compound management system. Bulk orders will be collated for reduced costs to positively impact bottom lines, extend funding, and guide future roadmaps. Lab operations will thus benefit from more structured data that can be fed into external integrations such as outside contract research organizations or molecule database managers. Lastly, with an embedded vector database showcasing all of the commercially available chemical space, we can then design future machine learning models to suggest compounds for primary screens and help the initial ideation for future research programs. 
At present, the market for procurement and management is fragmented. The current software-based applications are either unreliable, buggy, or just simply not user-friendly. The market has yet to appreciate the need for this niche so the industry standard consists of large players, like Sigma Aldrich, who typically dominate with large fleets of vendors but pricey subscription-based software applications. Other examples include SciFinder, a chemical compound database which actually allows input for vendor catalogs but is unfortunately limited in size and difficult to navigate. On the compound management side, I worked with Titian Mosaic, a larger sample management software, which ended up prioritizing its revenue from costly sell-side integrations as the only way for the customer to extract a functioning product. Or Quartzy, another software offering that focuses on inventory management and lab equipment procurement that was haphazardly integrated into a compound management tool. For many labs that lack the funds to spend on expensive software, they have no choice but to adopt standard of procedures (SOP) around Excel sheets passed down from researcher to researcher. All in all, this is a very niche space with independent vendors monopolizing with their own software tooling.

Q1 Collect user stories from across academia and industry for each step in the procurement and management pipeline || Develop an MVP that provides search and management functions across embedded vendor catalogs 
Q2 Pilot with non-profit and academic institutions to prioritize and iterate on procurement features || On board features for inventory management and order tracking 
Q3 Open source and publish the platform online for sign-up and public use
Q4 Pilot platform for biotech procurement and management teams || Partner with vendors for on-demand generation or shipping of compounds || Ideate for future platform updates

To achieve these goals, I would greatly benefit from working with those who have a strong background in chemistry or direct experience in high throughput chemistry within industry. Additionally, I am eager to learn from others who have experience in scaling a business and interacting with investors and financial models. I’m looking forward to working with future collaborators of diverse backgrounds. 

Compute costs:
Hosting an application both frontend and backend: 50 - 100 / month 
Provisioned database for embeddings of all vendor catalogs: 200 - 400 / month
Postgres database for application metadata: 100 - 200 / month
Provisioned server for large language model inference: 200 - 400 / month
External compute resources for testing and proof of concepts: 100 / month
Total cost / year: 14,400

Personnel costs:
Personal salary per year: 200,000 / year 
Travel + accommodation per year (1 onsite visit per quarter): 6,000 
Conference travel + accommodations: 6,000
Total cost / year: 212,000


    </p>
</body>
</html>
